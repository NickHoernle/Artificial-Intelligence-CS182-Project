\documentclass[11pt]{article}
\usepackage{common,graphicx,subfig,hyperref}

\pagenumbering{roman}
\title{CS182 Artificial Intelligence Project \\ \Large{Safe Cycling Route Planning}}
\author{Anna Sophie Hilgard, Nick Hoernle, and Nikhila Ravi}
\begin{document}
\maketitle{}

% % Some new environments for fancy cross-referencing
% \newenvironment{a_star_algorithm}[1][htb]
%   {\renewcommand{\algorithmcfname}{$A^{*} Star Algorithm$}% Update algorithm name
%    \begin{algorithm}[#1]
%   }{\end{algorithm}}


\setlength{\parindent}{2em}
\setlength{\parskip}{1em}
\renewcommand{\baselinestretch}{1.3}
\pagenumbering{arabic}

\section{Introduction}

Biker safety and biker safety awareness has been a topical issue for a number of years with the biker death toll at an unacceptably high rate (13 deaths in the past 5 years in Boston alone (**count of accidents in Cambridge - do we have a date attached here??**)). Current map applications like Google often route cyclists through busy streets and intersections, resulting in unnecessarily dangerous trips. The purpose of this project has been to explore AI graph search and local search algorithms to optimize a bike routing algorithm not only for `distance minimization', but also for `path safety' and `elevation comfort'. We explore the use of $A^{*}$ graph search under different cost and heuristic metrics to obtain a fast, yet reliable graph search between any two nodes on the intersection graph. Furthermore, we explore the use of local search to optimize for the ideal meeting point between two or more cyclists.

% \par The algorithm we chose to use for this problem is $A^{*}$ search with a variety of cost functions and heuristics incorporating distance, safety of a given route, and changes in elevation (also important for biking but not information Google maps currently considers).

% \par The graph search problem is directly analogous to techniques and ideas from the class: using intersections as nodes in the graph and road segments connecting intersections as paths, we are able to construct the city maps as directed graphs. From there, we can use data generated from a variety of sources to come up with approximate costs associated with paths and related heuristics at nodes.

% \par The optimization techniques we use are also direct applications of algorithms from the optimization portion of the course.

% Problem-specific adaptations were largely limited to the collection and interpretation of relevant data and the development of a cost function and relevant heuristics.

\section{Background and Related Work}

While our problem was fairly straightforward, we did do some research to get ideas for potential cost attributes and data sources. Our initial formulation of the problem, for example, did not include elevation differencing, but reading previous studies led us to believe that this was an important criterion \cite{pmbr}.

\section{Problem Specification}
The graph of intersections and nodes forms a highly connected state space (Cambridge has 1831 nodes, San Francisco has 18410 nodes, and each node typically has a branching factor of 4). While it is possible, searching the entire state space for San Francisco would involve considerable computation, on the order of $4^{18410}$ possible routes to explore, and this search space grows exponentially with additional nodes.
\par To compound this search space problem, we aimed to determine central meeting areas for a number of cyclists to use as a fair and safe meeting place. The search problem here is therefore not only to determine the best route from a start node to a goal but also to determine the best goal node, optimizing for minimal cost for all cyclists.
\par Initially, we implement an $A^{*}$ search algorithm. We then used that $A^{*}$ search as a baseline for determining the route from any starting point to some goal node and we run a local search layer on top of this to find the best meeting intersection between a number of cyclists. We tailored three cost functions and three heuristics for comparing the performance of the $A^{*}$ and Local Search (which depend on the $A^{*}$ algorithm).

\subsection{Cost Functions}
The problem that we are solving is of the general class of graph search problems. Given a strongly connected graph, we seek to minimize some cost function:
\begin{equation}
cost = \sum_{i=0}^n cost(path_i)
\end{equation}
given that:
\begin{itemize}
\item $path_0 \in Connections_{\text{(starting node)}}$
\item $path_i, path_{i+1} \in Connections_{node_i}$
% \item $path_i, path_{i-1} \in Connections_{node_k}$
\item $path_n \in Connections_{\text{(target node - 1)}}$
\end{itemize}

\noindent Specifically for our problem, we created three different cost functions:
\begin{align}\label{cost_fns}
cost_{distance\_only}(path_i) &= length_i \\
cost_{distance\_safety}(path_i) &= (\alpha \times length_i) \times  (\beta \times accidents_i) \\
cost_{distance\_safety\_elevation}(path_i) &= (\alpha \times length_i) \times  (\beta \times accidents_i) + abs(\Delta elevation_i)
\end{align}


\noindent Where $\alpha$ and $\beta$ are scaling multipliers to weight the relative magnitudes of the different cost measurements. We used a value of $\alpha = 10000$ to scale the coordinate based length measurement to a number on the same magnitude of $\Delta elevation$. $\beta$ was set to 5 to penalize the roads with accidents highly in the algorithm. These values can be tuned empirically.\par
\noindent In the optimization portion of our project, we seek to minimize the total cost to all parties:
\begin{equation}
min(\sum_j^n cost_j)
\end{equation}
where $cost_j$ is the cost to participant j.

\section{Approach}
\subsection{Data Structures}
Our primary data structures are an intersection graph, which is stored as a Python dictionary, and a connection dictionary, which is also stored as a Python dictionary. The intersection graph maps nodes (intersections) by id to a list of paths (road segments) from that node. The connection dictionary maps a connection (road segment) to its source node, sink node, and various cost parameters (in our case distance, number of bicycle crashes on that road segment, and change in elevation over that road segment).

\subsection{Data Collection, Extraction and Preprocessing}
In this case study, we were able to use open source geolocation data from Cambridge and San Francisco city councils. These departments further supplied data on the number of bike related accidents for various road segments. Lastly an elevation layer from the open GIS websites was used to infer the elevation of certain roads and intersections.

We tested our implementation on data from the cities of Cambridge, MA and San Francisco, CA. GIS location data is available on the local government websites in the form of a pandas geojson dataframe and was easily read into a pandas dataframe object using the geopandas library \footnote{\url{http://geopandas.org/}}.
\par
As discussed above, these geolocation data are used to create a set of nodes with coordinate positions and a number of connections which define the roads and the intersections that those roads are connected to. The data from Cambridge contained routing errors were some intersections were connected to other incorrect intersections resulting in roads that spanned the entire graph rather than simply connecting the two nearest neighboring intersections. The solution to this was to use the $geometry$ data within the Pandas geolocation dataframe and the $shapely$ \footnote{https://pypi.python.org/pypi/Shapely} graphing library to compare the actual road length to our interpolated distance for the road. If the interpolated distance was incorrect by more than a factor of 10, we made the assumption that the nodes were incorrectly tagged in the data and we dropped the connection attribute. The elevation and crash data was independently collected from the different government websites and the intersection id's were used to map this data into the `intersection' and `connection' graphs and dictionaries.
\par The resulting connected graphs for `Cambridge' and `San Francisco' are shown in figure \ref{connected_graphs}

\begin{figure}%
    \centering
    \subfloat[San Francisco]{{\includegraphics[width=7cm]{san_fran_map} }}%
    \qquad
    \subfloat[Cambridge]{{\includegraphics[width=7cm]{cambridge_map} }}%
    \caption{Connected graphs of the San Francisco and Cambridge maps with a route shown on the map (using only distance as the cost metric on the Cambridge but distance and safety on the San Francisco map).}
    \label{connected_graphs}%
\end{figure}

\subsection{$A^{*}$ Search}
$A^{*}$ is an adaptive graph search algorithm that is able to take different cost and heuristic functions as parameters and then traverses the graph based on the output of these functions. $A^{*}$ search was chosen over the uniform cost alternative due to the efficient graph search under a good heuristic. We note that while a simple heuristic is to use the Euclidean distance to the goal node, incorporating accident and elevation data is non-trivial and may lead to inconsistent heuristic functions.\par
Please refer to Appendix \ref{algorithms}, \nameref{a_star_algo} for a formal outline of the algorithm.

\subsubsection{Heuristic Functions}
We used three main heuristic functions for testing the $A^{*}$ algorithm. We firstly used a null heuristic that we use as a baseline to compare the other heuristics against. We used a simple euclidean distance heuristic that measures the distance from the current node i to the goal node as an admissible and consistent heuristic. Finally we used a heuristic that makes a simple delta elevation estimate from the current goal to the end goal and a minimum of the number of accidents on the connections from the current goal. This `combined heuristic' also included the euclidean distance element and a linear combination of these values was used.
\begin{align}\label{heuristic_fns}
heuristic_{null}(node_i) &= 0 \\
heuristic_{euclidean\_distance}(node_i) &= euclidean\_distance(node_i, goal)\\
\begin{split}
heuristic_{combined}(node_i) &= (\alpha \times euclidean\_distance(node_i, goal) \\ &\times  (\beta \times min(accidents\_node_i)) \\&+ abs(elevation\_difference(node_i, goal))
\end{split}
\end{align}

\subsection{Local Search: Simulated Annealing}
The Simulated Annealing Search involved initializing a centroid and iteratively hill climbing the space around that centroid to find a local optimum point. Initially, a temperature attribute is set high, such that the hill climbing algorithm accepts non-optimal nodes with a high probability. As the algorithm proceeds, and converges on a local optimum, the temperature is decreased such that the hill climbing becomes more deterministic.
\par
As the state space of the search graph is large, and the distance metric is highly interpretable, we opted to initialize the first centroid at the intersection that represents the Euclidean mean between all cyclists. Our aim was to initialize the centroid within the vicinity of an optimal meeting point and allow the high initial temperature to counteract any potential local optimum intersections that may have been encountered.
\par
Please refer to Appendix \ref{algorithms}, \nameref{annealing_algo} for a formal outline of the algorithm.

\subsection{Local Search: K-Beam Search}

K Beam search involved initializing a number of centroids within the state space of the graph and iteratively hill climbing from the K best centroids to find a local optimum.
\par
Please refer to Appendix \ref{algorithms}, \nameref{k_beam_algo} for a formal outline of the algorithm.

\section{Experiments}
% Analysis, evaluation, and critique of the algorithm and your
% implementation. Include a description of the testing data you used and
% a discussion of examples that illustrate major features of your
% system. Testing is a critical part of system construction, and the
% scope of your testing will be an important component in our
% evaluation. Discuss what you learned from the implementation.
We aimed to test:
\begin{itemize}
\item The effect of the varying cost functions on the routes that were found.
\item The effect of the $A^{*}$ heuristic on the speed of search (and consistency of the route)
\item The efficiency and effectiveness of the resulting search
\end{itemize}

\subsection{Testing $A^{*}$ Search}
We randomly selected nodes within the two graphs and ran $A^{*}$ search to find the optimal route through the map. The figure \ref{connected_san_fran} shows an example of $A^{*}$ finding an optimal route under two different costs.

\begin{figure}
\label{connected_san_fran}
\center
\caption{Paths between nodes in San Francisco. Blue path optimizes for distance only, green path avoids previous bicycle accidents, and red path minimizes altitude changes. Overlaid with an altitude plot of San Francisco, we can clearly see the red path avoiding a hill.}
\includegraphics[width=0.6\textwidth]{sf_new_plot_2.png}
\end{figure}

\par
We then ran an iteration of 100 simulations for each cost function (\ref{cost_fns}) and each heuristic function (\ref{heuristic_fns}). Specifically the null and euclidean heuristics are both expected to find the optimal route. The euclidean heuristic should explore fewer nodes than the null heuristic. When the cost function is simple distance or simple distance and safety, the combined heuristic is neither admissible nor is it consistent as it is penalizing nodes for a cost that is not encoded in the algorithm. We expect to see this algorithm find a `longer than necessary optimal path'. However, when the cost function also encodes all of these costs, we now expect the combined heuristic to out perform the other heuristics on all accounts. Please refer to \nameref{results} for a further discussion on the above.


% \item{Evaluation:} We went through a few iterations of tuning the parameters in our cost function to get the appearance of the graphs to mimic what we think we'd want as cyclists. Because the cost in our problem is qualitative rather than explicitly quantitative, we were largely forced to estimate parameters based on what we thought would be reasonable rather than deriving them from empirical data of some sort. That said, we all felt that with our final parameters the algorithm was doing a reasonable job at generating routes we would want.

% \begin{table}[H]
%   \centering
%   \begin{tabular}{lll}
%     \toprule
%     & Time & Total Cost \\
%     \midrule 
%     Simulated Annealing & &\\
%     K-Beam Search & &\\
%     \bottomrule
%   \end{tabular}
%   \caption{Description of the results.}
% \end{table}

\subsection{Testing Local Search}

\par
K Beam search involved initializing a number of centroids within the state space of the graph and iteratively hill climbing from the K best centroids to find a local optimum.
\par
We ran Simulated Annealing and K-Beam Search on a number of different iterations of randomly selected nodes. While both algorithms can be tuned to run faster (by reducing the temperature faster for simulated annealing and reducing `k' for k-beam search at the cost of being more susceptible to local minima) we can make a reasonable comparison of the two algorithms in terms of their total runtime resulting cost of the returned node.

\section{Results}\label{results}

\subsection{$A^{*}$ Search Results}

\subsection{Local Search Results}

Comparison of routes found by three different cost functions to $A^{*}$ with three different heuristics: \\

\begin{figure}[H]
\caption{Basic road cost under three different heuristics. Here we would expect the combined heuristic to significantly underperform the null heuristic and euclidean heuristic in terms of distance as the heuristic does not properly model the cost function. Therefore the heuristic is both inadmissible and inconsistent for this problem. }
\includegraphics[width=1\textwidth]{../images/cost_1.png}
\end{figure}

\begin{figure}[H]
\caption{Safety road cost under three different heuristics. Again, we expect to see the combined heuristic underperform the null heuristic and euclidean heuristic as the heuristic does not properly model the cost function and is neither admissible nor consistent }
\includegraphics[width=1\textwidth]{../images/cost_2.png}
\end{figure}

\begin{figure}[H]
\caption{Safety, distance, and elevation cost under three different heuristics. Here we still do not expect the combined heuristic to find the ideal solution, as the heuristic is not consistent, but it should do a reasonable job and significantly decrease the nodes expanded.}
\includegraphics[width=1\textwidth]{../images/cost_3.png}
\end{figure}

\begin{figure}[H]
\caption{Total distance, total nodes expanded, and total elevation change for the three cost functions under uniform cost search.}
\includegraphics[width=1\textwidth]{../images/total_costs.png}
\end{figure}

TODO: Comparison of K-beam search and Simulated annealing: time to find solution vs total cost of solution found for a number of trials

\section{Discussion}

{Critique:} Our algorithms could have been made to run somewhat faster by incorporating pruning strategies but we were generally satisfied with run times. Additionally, it was difficult to generate a very useful admissible heuristic for bike crashes because one could almost always find an extremely convoluted path to avoid almost all of them, and so to have a heuristic which is always $le$ the actual cost to the goal is often not that informative.

The graph search approach is a very straightforward and satisfactory solution to this problem. We felt that our results were very reasonable given our preexisting knowledge of Cambridge and San Francisco streets. \\
A couple takeaways from this project:
\begin{itemize}
\item As always, you're only as good as your data. We had some lofty goals for the data that we'd be able to collect and use for this project, but even the data we ended up using was harder to collect and map that we anticipated, and much of the crash data was a few years old. Cambridge and San Francisco are relatively tech-forward cities, so I can imagine this would be even more difficult in most other environments
\item It was interesting to see how our algorithm scaled to the larger map of San Francisco. To plan routes through a larger area, it's clear that we would have to adapt the algorithm to get the runtime within a reasonable range. In particular, we found in our reading that many routing engines actually use inadmissible heuristics for these tasks and still find reasonable results but in a much quicker time.
\end{itemize}

In future work, we could develop faster algorithms by using pruning procedures or finding ways to run expensive operations in parallel or vectorized forms. We could develop more sophisticated models of biking comfort by also including road construction data and pothole reports.

Bayesian Inference:
Calculating the number of accidents per road segment is a good estimate of how dangerous a given road segment is, but probably a better indicator would be accidents per units of bicycle traffic. If we were able to collect bicycle traffic data for each road segment, we could then calculate the Bayesian probability of 
P(road segment | accident) as proportional to P(accident | road segment) * P(road segment). In particular, we may be over-penalizing roads with a large amount of cycling traffic.


Pruning techniques:
To make the search algorithms run faster, we could consider a number of pruning
techniques to reduce feasible paths at each node.

\appendix
\section{System Description}

The easiest way to use our system is to open the provided iPython notebook and run each of the cells. All of the supporting functions can be found in $final\_project.py$.\footnote{$final\_project.py$: \url{https://github.com/NickHoernle/Artificial-Intelligence-CS182-Project/blob/master/final_project.py}}\footnote{$final\_project.ipynb$: \url{https://github.com/NickHoernle/Artificial-Intelligence-CS182-Project/blob/master/final_project.ipynb}}

\section{Group Makeup}

\begin{enumerate}
\item Nick Hoernle
\begin{enumerate}
\item Creation of graph dictionary structure and $A^{*}$search algorithm
\item Simulated annealing
\end{enumerate}
\item Nikhila Ravi
\begin{enumerate}
\item K-Beam Search
\item Visualization and analysis of results of graph search algorithms
\end{enumerate}
\item Anna Sophie Hilgard
\begin{enumerate}
\item Construction of Datasets
\item Research and Implementation of more complicated cost functions and heuristics
\end{enumerate}
\end{enumerate}

\section{Algorithms}\label{algorithms}
\begin{algorithm}[H]
  \caption{$A^{*}$ Search Algorithm}\label{a_star_algo}
  \begin{algorithmic}
    \Function{A-Star-Search}{$graph, start node, target node$}
    \State{$node \gets $a node with $ \textsc{state}=start node$}
    \State{$\textsc{path-cost} \gets \textbf{heuristic}(start node, target node)$}
    \State{$frontier\gets $ a priority queue ordered by $\textsc{path-cost} + \textbf{heuristic}(node, target node)$ with $node$ as the only element}
    \State{$explored \gets $ an empty set}
    \Loop
    \If{$\textsc{Empty?}(frontier)$}
    \State \textbf{return failure}
    \EndIf
    \State{$node \gets \textsc{pop}(frontier)$ /*chooses the lowest cost+heuristic node in $frontier$ */}
     \If{$node == targetnode$}
    \State {\textbf{return} \textsc{solution}($node$)}
    \EndIf
    \State{add node.\textsc{State} to $explored$}
    \For{ \textbf{each} $path$ in \textsc{Paths}($node$)}
    \State{$child \gets$ \textbf{child-node}($node, path$)}
    \If {$child$.\textsc{State} is not in $explored$ or $frontier$}
    \State{$frontier \gets$ \textbf{insert}($child, frontier$)}
    \ElsIf  {$child$.\textsc{State} is in $frontier$ with higher \textsc{path-cost} + heuristic}
    \State{replace that $frontier$ node with $child$}
    \EndIf
    \EndFor
    \EndLoop
    \EndFunction{}
  \end{algorithmic}
  \caption{A-Star Search}
\end{algorithm}

\begin{algorithm}[H]
  \caption{Simulated Annealing Algorithm}\label{annealing_algo}
  \begin{algorithmic}
    \Function{Simulated Annealing Meeting Spot}{$graph, startingpts, cost, heuristic$}
    \If{$\textbf{length}(startingpts)<2$}
    \State \textbf{return error}
    \EndIf
    \State{$current \gets$ \textbf{mean}$(startingpts)$.\textsc{closest-node}}
    \State{$temperature \gets e^{10}$}
    \State{$\gamma \gets .5$ /*schedule to manage $temperature$ */}
    \While{$temperature > e^{-2}$}
      \State{$temperature \gets temperature*\gamma$}
      \State{$next \gets$ a randomly selected $child$ of $current$}
      \State{$current.\textsc{value} \gets \sum_{pt \in startingpts}\textbf{cost}(pt, centroid$)}
      \State{$next.\textsc{value} \gets \sum_{pt \in startingpts}\textbf{cost}(pt, next$)}
      \State{$\Delta E \gets next.\textsc{value} - current.\textsc{value}$}
      \If {$\Delta E > 0$}
      \State{$current \gets next$}
      \Else
       \State{$current \gets next$ with probability $e^{\Delta E / temperature}$}
      \EndIf
    \EndWhile
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\begin{algorithm}[H]
  \caption{K Beam Search Algorithm}\label{k_beam_algo}
  \begin{algorithmic}
    \Function{K-Beam Search Meeting Spot}{$k, graph, startingpts, cost, heuristic$}
    \If{$\textbf{length}(startingpts)<2$}
    \State \textbf{return error}
    \EndIf \\
    \State{$\{candidatenodes\} \gets \,node\, \forall \,node \in graph $ s.t. \\ $node.x \ge min(startingpts.x) \& \,node.x \le max(startingpts.x) \&$ \\ $node.y \ge min(startingpts.y) \& \,node.y \le max(startingpts.y)$} \\
    \State{$point_i \gets$ a randomly selected $node \in \{candidatenodes\} \forall i \le k$}
    \State{$best.\textsc{value} \gets min_{i\le k}(\sum_{pt \in startingpts}\textbf{cost}(pt, point_i))$}
    \While{\textbf{True}}
      \State{$\{nextcosts \} \gets \sum_{pt \in startingpts}\textbf{cost}(pt, child_i) \forall i \le k, child_i \in \textsc{Paths}(point_i).endnode $}
      \State{$point_i \gets$ i-th least $node \in \{nextcosts\} \forall i \le k$}
      \State{$next.\textsc{value} \gets \sum_{pt \in startingpts}\textbf{cost}(pt, point_1$)}
      \If {$next.\textsc{value} < best.\textsc{value}$}
      \State{$best \gets next$}
      \Else
       \State{\textbf{break}}
      \EndIf
      \State{\textbf{return} $best$}
    \EndWhile
    \EndFunction{}
  \end{algorithmic}
\end{algorithm}

\bibliographystyle{plain} 
\bibliography{project-template}

\end{document}
